#!/bin/bash
#
# Copyright 2014,2015,2016,2017,2018,2019,2020 Security Onion Solutions, LLC
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

# Written by:
# Doug Burks
# Fixes contributed by:
# Stephane Chazelas
# Shane Castle
# Wes Lambert
# Freq_server and Domain_stats components written by:
# Justin Henderson

# Import settings file
if [ -f /etc/nsm/securityonion.conf ]; then
   source /etc/nsm/securityonion.conf
else
   echo "Missing /etc/nsm/securityonion.conf file!" && exit 1
fi

# make sure if statements using wildcards for filenames don't equal true when no files exist
shopt -s nullglob

# Define a banner to separate sections
banner="========================================================================="

# Check for root
[ "$(id -u)" -ne 0 ] && echo "This script must be run using sudo!" && exit 1

header() {
  printf '%s\n' "$banner" "$*" "$banner"
}

remove_ansi_escapes() {
  sed $'s/\e[^mk]*[mk]//g;s/[\e\r]//g'
}

# Options
usage()
{
cat <<EOF

Security Onion Statistics

     Options:

        -h              This message
        -a              Show all installed Security Onion packages

Usage: $0
EOF
}

# Check flags
ALL_PKGS=0
while getopts ":ha" OPTION
do
     case $OPTION in
         h)
                usage
                exit 0
                ;;
         a)
                ALL_PKGS=1
             ;;
     esac
done

# Determine sensor interfaces for packet loss stats
INTERFACES=""
NUM_INTERFACES=0
SENSORTAB="/etc/nsm/sensortab"
if [ -s $SENSORTAB ]; then
	INTERFACES=$(grep -v "#" $SENSORTAB | awk '{print $4}')
	NUM_INTERFACES=$(grep -v "#" $SENSORTAB | wc -l)
fi

# Text formatting
if [ -t 1 ];then
	underline=`tput smul`
	normal=`tput sgr0`
else
	:
fi

# Begin output
header "Service Status"
so-status 2>&1 | remove_ansi_escapes

echo
header "Interface Status"
if [ "$ELASTICSEARCH_ENABLED" = "yes" ]; then
        NOT_VETH=`ls -A /sys/class/net | grep -v veth`
        for i in $NOT_VETH; do
                ifconfig $i
        done
        CONTAINERS=`docker ps --format '{{.Names}}'`
        for i in $CONTAINERS; do
		echo
                echo $i
                echo '-------------------------------------------------------------------------'
                ETH_LIST=`docker exec $i sh -c 'ls /sys/class/net/eth*/iflink'`
		for interface in $ETH_LIST; do
                        ETH_SHORT=`echo $interface | cut -d'/' -f5`
                        INT_INT=`docker exec $i cat $interface`
                        EXT_INT=`grep -w "$INT_INT" /sys/class/net/veth*/ifindex | cut -d'/' -f5`
                        echo "("$ETH_SHORT")"
                        ifconfig $EXT_INT
                done
        done

else
        ifconfig
fi

echo
header "Link Statistics"
ip -s -s link

echo
header "Disk Usage"
df -h

echo
header "Network Sockets"
lsof -nP -i

if [ -f /var/log/nsm/pulledpork.log ]; then
	echo
	header "IDS Rules Update"
	date=$(date +'%a %b %_d')
	tac /var/log/nsm/pulledpork.log |
	  grep 'UTC' -m1 -B 1000 |
	  tac |
	  sed "/^$date/,\$!d;/./!d;/An error occurred: WARNING: /d" |
	  remove_ansi_escapes
fi

echo
PROCS=`nproc --all`
header "CPU Usage"
echo "Load average for the last 1, 5, and 15 minutes:"
cat /proc/loadavg | awk '{print $1,$2,$3}'
echo "Processing units: $PROCS"
echo "If load average is higher than processing units,"
echo "then tune until load average is lower than processing units."
echo
# Get the first six lines of top output (summary)
top -b -n1 |head -6
# Use "ps" to get a process listing and sort it by cpu usage
ps -eo pcpu,pmem,args --sort -pcpu

if [ -d /nsm/sensor_data ] && [ $NUM_INTERFACES -gt 0 ]; then
	echo
	FREQUENCY=`grep -A1 packets_received /var/ossec/etc/ossec.conf | tail -1 | cut -d\> -f2 | cut -d\< -f1`
	header "Packets received during last monitoring interval ($FREQUENCY seconds)"
	/usr/sbin/sostat-interface-delta
	echo
	header "Packet Loss Stats"
	echo
	echo "${underline}NIC${normal}:"
	echo
	for IFACE in $INTERFACES;do
		echo "$IFACE:" && echo && echo `ifconfig $IFACE |awk '/dropped:/ {print $1,$2,$4}'` && echo ""
	done
	# sostat: don't show pf_ring output if af_packet in use #1623
	# https://github.com/Security-Onion-Solutions/security-onion/issues/1623
	if [ -f /proc/net/pf_ring/info ] && [ $(grep "Total rings" /proc/net/pf_ring/info | awk '{print $4}') -gt 0 ]; then
		echo "-------------------------------------------------------------------------"
		echo
		echo "${underline}pf_ring${normal}:"
		echo
		if [ $(ls /proc/net/pf_ring/ | wc -l) -gt 0 ]; then
			for i in /proc/net/pf_ring/*-* ; do
				APP_NAME=`grep "Appl. Name" $i | awk '{print $4}'`
                        	PF_TOT_IN=`grep "Tot Packets" $i | awk '{print $4}'`
	                        PF_TOT_LOST=`grep "Tot Pkt Lost" $i | awk '{print $5}'`
        	                if [[ -n $PF_TOT_LOST ]] && [[ $PF_TOT_LOST -gt 0 ]] ; then
                	                PF_PERCENT_LOST=$(echo "scale=2 ; $PF_TOT_LOST * 10/$PF_TOT_IN * 10" | bc)
	                        else
        	                	PF_PERCENT_LOST=0
                	        fi
                        	echo "Appl. Name: $APP_NAME"
				echo "Tot Packets: $PF_TOT_IN"
				echo "Tot Pkt Lost: $PF_TOT_LOST"
				echo "Loss as a percentage: $PF_PERCENT_LOST"
				echo
			done
		fi
	fi
	echo "-------------------------------------------------------------------------"
	echo
	echo "${underline}IDS Engine ($ENGINE) packet drops${normal}:"
	echo
	if [ "$ENGINE" = "suricata" ]; then
		for i in /nsm/sensor_data/*/stats.log; do
			echo "$i"
			echo

			# Grab the latest stats section from the log
			LATEST_STATS=$(grep -A1000 "$(grep '^Date: ' $i | tail -1)" $i)

			# Did Suricata report any drops?
			if [ $( echo "$LATEST_STATS" | grep -c drop ) -ne 0 ]; then
				SURI_CAPTURE=$(echo "$LATEST_STATS" | grep -m1 "capture.kernel_packets" | awk '{print $5}')
				SURI_DROPS=$(echo "$LATEST_STATS" | grep -m1 "capture.kernel_drops" | awk '{print $5}')
				SURI_PCT=$(echo "scale=2 ; $SURI_DROPS * 10/$SURI_CAPTURE * 10" | bc)
				echo $SURI_PCT% Loss
			else
				echo "No packet drops reported."
			fi

			echo
		done
        else
		for i in /nsm/sensor_data/*/snort-*.stats; do
			if grep -q '^[^#]' "$i"; then
				echo -n "$i last reported pkt_drop_percent as "
				grep -v '^#' "$i" |tail -n 1 |cut -d\, -f2
			else
				echo "ERROR: No stats found in $i"
			fi
		done
	fi
	echo "-------------------------------------------------------------------------"
	echo
        TMP=`mktemp`
        su sguil -c '/opt/zeek/bin/zeekctl netstats 2>&1 | grep -v "Warning: ZeekControl plugin uses legacy BroControl API. Use" | grep -v "import BroControl.plugin" | grep -v "^$" ' > $TMP
        if [ -s $TMP ]; then
                echo "${underline}Zeek${normal}:"
                echo
		echo -n "Average packet loss as percent across all Zeek workers: "
                cat $TMP | \
		sed 's/[a-z]*=//g' | \
		awk '{ drop += $4 ; link += $5 } \
		END { if ( link >=1 ) printf("%f\n", ((drop/NR) / (link/NR)) * 100); else print("No packets seen."); }'
                echo
                cat $TMP
                echo
                if [ -f /nsm/zeek/logs/current/capture_loss.log ]; then
			echo "Capture Loss:"
			echo
			# If Zeek is writing logs in json format, then parse with jq
			if grep -q '^@load json-logs' /opt/zeek/share/zeek/site/local.zeek; then
                                CL_LOG="/nsm/zeek/logs/current/capture_loss.log"
                                PERCENT_LOST=$(cat $CL_LOG | jq .percent_lost | sort -u)
                                for i in $(cat $CL_LOG | jq .peer | sort -u); do
                                        PEER=$(echo $i | sed s'/"//g')
                                        echo "$PEER: $PERCENT_LOST"
                                done
			# If Zeek is writing logs in tsv format, then parse with zeek-cut
                        else
                                echo "`/opt/zeek/bin/zeek-cut peer percent_lost < /nsm/zeek/logs/current/capture_loss.log | sort -u`"
                        fi
			echo
			echo "If you are seeing capture loss without dropped packets, this"
			echo "may indicate that an upstream device is dropping packets (tap or SPAN port)."
		else
			echo "No capture loss reported."
		fi
		rm $TMP
	fi
	echo
	echo "-------------------------------------------------------------------------"
	if ls /var/log/nsm/*/netsniff-ng.log > /dev/null 2>&1; then
		echo
		echo "${underline}Netsniff-NG${normal}:"
		for i in /var/log/nsm/*/netsniff-ng.log; do
			if grep -q -e "-[1-9]*)" "$i"; then
				RCVD=$(cat $i | tr ').(' '\n' |grep "^+" | sed 's|+||g' | sed 's|/-| |g' |awk '{print $1}' | paste -sd+ - | bc)
				DRPD=$(cat $i | tr ').(' '\n' |grep "^+" | sed 's|+||g' | sed 's|/-| |g' |awk '{print $2}' | paste -sd+ - | bc)
				let TOT_PKTS=RCVD+DRPD
				DRPD_PCT=`echo 'scale=2; '$DRPD'*100/'$TOT_PKTS''|bc`
				echo
				echo Percentage of packets dropped:
				echo
				echo " $i -- $DRPD_PCT"
				echo
			else
				echo
				echo "0 Loss"
	                fi
		done
	fi
	echo
	header "PF_RING"
        cat /proc/net/pf_ring/info
	echo
	header "Log Archive"
	for i in /nsm/sensor_data/*; do
		DAYS=`ls $i/dailylogs/ | wc -l`
		echo "$i/dailylogs/ - $DAYS days"
		cd $i/dailylogs
		du --max-depth=1 -h|sort -k2
		cd ->/dev/null
		echo
	done
	DAYS=`ls /nsm/zeek/logs/ | grep -v current | grep -v stats | wc -l`
	echo "/nsm/zeek/logs/ - $DAYS days"; cd /nsm/zeek/logs/; du --max-depth=1 -h |sort -k2; cd ->/dev/null
fi
if [ -d /var/lib/mysql/securityonion_db ]; then
	echo
	header "Sguil Uncategorized Events"
	mysql --defaults-file=/etc/mysql/debian.cnf -Dsecurityonion_db -e "SELECT COUNT(*) FROM event WHERE status=0"
	echo
	header "Sguil events summary for yesterday"
	# List all sigs from yesterday that are not URLs captured by http_agent descending by count
	mysql --defaults-file=/etc/mysql/debian.cnf -Dsecurityonion_db -e "select count(*) as Totals, CONCAT(event.signature_gen, ':', event.signature_id) as 'GenID:SigID', event.signature as Signature from event where event.signature_gen != 10001 and event.signature_id != 420042 and event.timestamp<curdate() and event.timestamp>DATE_ADD(CURDATE(), INTERVAL -1 DAY) group by event.signature order by Totals desc;"
	mysql --defaults-file=/etc/mysql/debian.cnf -Dsecurityonion_db -e "select count(*) as Total from event where event.signature_gen != 10001 and event.signature_id != 420042 and event.timestamp<curdate() and event.timestamp>DATE_ADD(CURDATE(), INTERVAL -1 DAY);"
	echo
	header "Top 50 All time Sguil Events"
	mysql --defaults-file=/etc/mysql/debian.cnf -Dsecurityonion_db -e "select count(*) as Totals, CONCAT(event.signature_gen, ':', event.signature_id) as 'GenID:SigID', event.signature as Signature from event where event.signature_gen != 10001 and event.signature_id != 420042 group by event.signature order by Totals desc limit 50;"
	mysql --defaults-file=/etc/mysql/debian.cnf -Dsecurityonion_db -e "select count(*) as Total from event where event.signature_gen != 10001 and event.signature_id != 420042;"
	# check for active http_agent
	num_http_agents=$(mysql --defaults-file=/etc/mysql/debian.cnf -Dsecurityonion_db -e "select * from sensor where agent_type='http' and active='Y';" | wc -l)
	if [ $num_http_agents -gt 0 ]; then
		echo
		header "Top 50 URLs for yesterday"
		mysql --defaults-file=/etc/mysql/debian.cnf -Dsecurityonion_db -e "select count(*) as Totals, event.signature as Signature from event where event.signature_gen = 10001 and event.signature_id = 420042 and event.timestamp<curdate() and event.timestamp>DATE_ADD(CURDATE(), INTERVAL -1 DAY) group by event.signature order by Totals desc limit 50;"
		mysql --defaults-file=/etc/mysql/debian.cnf -Dsecurityonion_db -e "select count(*) as Total from event where event.signature_gen = 10001 and event.signature_id = 420042 and event.timestamp<curdate() and event.timestamp>DATE_ADD(CURDATE(), INTERVAL -1 DAY);"
	fi
fi

if [ -f /var/log/apt/history.log ]; then
	echo
	header "Last update"
	tail /var/log/apt/history.log
fi

if [ $(/usr/sbin/so-apt-check --human-readable | grep -c '0') -ne 2 ]; then
        echo
        header "Available updates"
        /usr/sbin/so-apt-check --human-readable
        echo
        echo "Run 'sudo soup' to install the latest updates."
fi

if [ "$ELSA" = "YES" ]; then
        echo
        header "ELSA"
	echo "Syslog-ng"
        echo "Checking for process:"
	pgrep -af /usr/sbin/syslog-ng
        echo "Checking for connection:"
	nc -4 -vz localhost 514 2>&1
	echo
        echo "MySQL"
        echo "Checking for process:"
        pgrep -af /usr/sbin/mysqld
        echo "Checking for connection:"
        [ -d /var/lib/mysql/securityonion_db ] && nc -4 -vz localhost 3306 2>&1 || nc -4 -vz localhost 50000 2>&1
        echo
        echo "Sphinx"
        echo "Checking for process:"
        pgrep -af /usr/bin/searchd
        echo "Checking for connection:"
        nc -4 -vz localhost 9306 2>&1
        echo
        echo "ELSA Buffers in Queue:"
        ls -al /nsm/elsa/data/elsa/tmp/buffers/ | wc -l
        echo
        echo "ELSA Directory Sizes:"
        du --max-depth=0 -h /nsm/elsa/data /var/lib/mysql/syslog /var/lib/mysql/syslog_data
        echo
	OFFSET="2"
	if [ -f /etc/elsa_web.conf ] && grep default_start_time_offset /etc/elsa_web.conf >/dev/null 2>&1; then
		OFFSET=`grep default_start_time_offset /etc/elsa_web.conf | awk '{print $2}' | cut -d, -f1`
	fi
	echo "ELSA Index Date Range"
	echo "If you don't have at least $OFFSET full days of logs in the Index Date Range,"
	echo "then you'll need to increase log_size_limit in /etc/elsa_node.conf."
	mysql --defaults-file=/etc/mysql/debian.cnf -Dsyslog -e "SELECT MIN(start), MAX(end) FROM syslog.v_indexes"
	echo
        if [ -d /var/lib/mysql/securityonion_db ]; then
                # Master server
		if grep "http://127.0.0.1:50" /etc/elsa_web.conf >/dev/null 2>&1; then
                	echo "ELSA Log Node SSH Tunnels:"
			(echo "PORT NODE IP/STATUS"
			grep "http://127.0.0.1:50" /etc/elsa_web.conf | awk '{print $2}' | cut -d\/ -f3 | sort | while read PORT; do
				NAME=$(grep -B1 $PORT /etc/elsa_web.conf | head -1 | cut -d\" -f2)
				PORT_ONLY=$(echo $PORT | cut -d\: -f2)
				if lsof -nP -i |grep "$PORT (LISTEN)" >/dev/null 2>&1; then
					lsof -nP -i |grep "$PORT (LISTEN)" | awk '{print $9,$2}' | while read PORT PID; do
						IP=`lsof -nP -i |grep "^sshd" | awk '{print $2,$9}' |grep "^$PID" |grep ":22" |awk '{print $2}' |cut -d\> -f2 | cut -d\: -f1 | head -1`
						echo "$PORT_ONLY $NAME $IP"
					done
				else 
					echo "$PORT_ONLY $NAME DISCONNECTED";
				fi
			done) | column -t
		fi
        else
                # ELSA Log Node
                echo "autossh"
                echo "Checking for process:"
                pgrep -af autossh
                echo
                echo "Checking APIKEY:"
                APIKEY=`grep '"apikey": "' /etc/elsa_web.conf | awk '{print $2}' | sed 's|"||g'`
                source /root/.ssh/securityonion_ssh.conf
                APIKEY_REMOTE=`ssh $SSH_USERNAME@$SERVERNAME -i /root/.ssh/securityonion grep -A2 $ELSA_PORT /etc/elsa_web.conf | grep apikey | awk '{print $2}' | sed 's|"||g'`
                [ "$APIKEY" = "$APIKEY_REMOTE" ] && echo "APIKEY matches server." || echo "APIKEY not found on master server."
                echo
                echo "starman"
                echo "Checking for processes:"
                pgrep -af starman
        fi
	err_arr=($(ps -ax | grep -i cron.pl | grep -v grep | awk '{print $1}'))
	if [[ ${#err_arr[@]} -gt 1 ]];then
		echo "*** WARNING: Multiple cron.pl processes detected! ***"
		echo
		for i in "${err_arr[@]}"
		do
			PS_START=$(ps -p $i -o lstart=)
			PS_DURATION=$(ps -p $i -o etime=)
			echo "PID: " $i " --- " "Start time: " $PS_START " --- " "Duration:" $PS_DURATION
		done
		echo
		echo "Potentially related errors in /nsm/elsa/data/elsa/web.log:"
		echo
		GREP_ERROR=$(grep -E 'failed|* ERROR' /nsm/elsa/data/elsa/log/web.log)
		if [[ ! -z "$GREP_ERROR" ]]; then
			echo "$GREP_ERROR"
			echo
		fi
		GREP_QID=$(grep -E 'Duplicate entry' /nsm/elsa/data/elsa/log/web.log)
		if [[ ! -z "$GREP_QID" ]]; then
			echo $GREP_QID
			echo
			echo "There may be a duplicate qid issue with one of the entries in the saved_results table of the elsa_web database:"
			echo
			mysql --defaults-file=/etc/mysql/debian.cnf -Delsa_web -e 'select * from saved_results'
			echo
		fi
	fi
fi

if [ "$ELASTICSEARCH_ENABLED" = "yes" ]; then
	
	source /usr/sbin/so-elastic-common

	TOT_NODES=$(curl $ELASTICSEARCH_AUTH -s "$ELASTICSEARCH_HOST:$ELASTICSEARCH_PORT/_cluster/stats?pretty" | jq ._nodes.total)
	#SUCCESS_NODES=curl $ELASTICSEARCH_AUTH "$ELASTICSEARCH_HOST:$ELASTICSEARCH_PORT/_cluster/stats?pretty" | jq ._nodes.successful`
	FAIL_NODES=$(curl $ELASTICSEARCH_AUTH -s "$ELASTICSEARCH_HOST:$ELASTICSEARCH_PORT/_cluster/stats?pretty" | jq ._nodes.failed)
	CLUST_NAME=$(curl $ELASTICSEARCH_AUTH -s "$ELASTICSEARCH_HOST:$ELASTICSEARCH_PORT/_cluster/stats?pretty" | jq .cluster_name)
	TOT_INDICES=$(curl $ELASTICSEARCH_AUTH -s "$ELASTICSEARCH_HOST:$ELASTICSEARCH_PORT/_cluster/stats?pretty" | jq .indices.count)
	TOT_SHARDS=$(curl $ELASTICSEARCH_AUTH -s "$ELASTICSEARCH_HOST:$ELASTICSEARCH_PORT/_cluster/stats?pretty" | jq .indices.shards.total)
	CLUST_STATUS=$(curl $ELASTICSEARCH_AUTH -s "$ELASTICSEARCH_HOST:$ELASTICSEARCH_PORT/_cluster/stats?pretty" | jq .status)
	FREE_MEM=$(curl $ELASTICSEARCH_AUTH -s "$ELASTICSEARCH_HOST:$ELASTICSEARCH_PORT/_cluster/stats?pretty" | jq .nodes.os.mem.free_percent)
	TOT_DOCS=$(curl $ELASTICSEARCH_AUTH -s "$ELASTICSEARCH_HOST:$ELASTICSEARCH_PORT/_cluster/stats?pretty" | jq .indices.docs.count)
	TOT_SIZE=$(curl $ELASTICSEARCH_AUTH -s "$ELASTICSEARCH_HOST:$ELASTICSEARCH_PORT/_cluster/stats?pretty" | jq .indices.store.size_in_bytes)
	ES_RUNNING=$(docker ps | grep so-elasticsearch)
	LS_RUNNING=$(docker ps | grep so-logstash)
	KIB_RUNNING=$(docker ps | grep so-kibana)
	ELAST_RUNNING=$(docker ps | grep so-elastalert)
	CURAT_RUNNING=$(docker ps | grep so-curator)
	FREQ_RUNNING=$(docker ps | grep so-freqserver)
	DOMAINSTATS_RUNNING=$(docker ps | grep so-domainstats)
	EVENT_COUNT=$(curl $ELASTICSEARCH_AUTH -s "$ELASTICSEARCH_HOST:$ELASTICSEARCH_PORT/*/_stats" | jq ._all.total.docs.count)
	AVG_EVENT_SIZE=$(echo $(($(curl $ELASTICSEARCH_AUTH -s "$ELASTICSEARCH_HOST:$ELASTICSEARCH_PORT/*/_stats" | jq ._all.total.store.size_in_bytes) / $(curl $ELASTICSEARCH_AUTH -s "$ELASTICSEARCH_HOST:$ELASTICSEARCH_PORT/*/_stats" | jq ._all.total.docs.count)))
)
	
	
	echo
        header "Elasticsearch"
	if [ "$ES_RUNNING" ]; then
                echo
                echo "Elasticsearch is running."        
                echo
                echo Cluster Name: $CLUST_NAME
                echo Cluster Status: $CLUST_STATUS
                echo Total Nodes: $TOT_NODES
                echo Failed Nodes: $FAIL_NODES
                echo Total Indices: $TOT_INDICES
                echo Total Shards: $TOT_SHARDS
                echo Total Documents: $TOT_DOCS
                echo Total Size: $(($TOT_SIZE/10**6))MB
                echo Free Memory: $FREE_MEM%
                echo Total Number of Events:  $EVENT_COUNT
		echo "Avg. Event Size (In Bytes): $AVG_EVENT_SIZE"
		echo
		docker stats --no-stream so-elasticsearch
        else
                echo
                CLUST_NAME=$(grep cluster.name /etc/elasticsearch/elasticsearch.yml | awk '{print $2}'|sed -e 's/^"//' -e 's/"$//')
                echo && echo -e "Elasticsearch is not running.\n\nTry starting it with:\n\n'sudo so-elastic-start'\n OR\n'sudo so-elasticsearch-start'\n\n\nIf that does not work, try checking /var/log/elasticsearch/"$CLUST_NAME".log for clues."
        fi

	if [ "$LOGSTASH_ENABLED" = "yes" ]; then
        QUEUE_STORAGE_TYPE=$(curl -s "$LOGSTASH_HOST:$LOGSTASH_PORT/_node/stats" | jq .pipelines.main.queue.data.storage_type)
	QUEUE_FREE_SPACE=$(curl -s "$LOGSTASH_HOST:$LOGSTASH_PORT/_node/stats" | jq .pipelines.main.queue.data.free_space_in_bytes)
	QUEUE_PATH="/nsm/logstash/queue/main"
	QUEUE_MAX_UNREAD=$(curl -s "$LOGSTASH_HOST:$LOGSTASH_PORT/_node/stats" | jq .pipelines.main.queue.capacity.max_unread_events)
	QUEUE_MAX_SIZE=$(curl -s "$LOGSTASH_HOST:$LOGSTASH_PORT/_node/stats" | jq .pipelines.main.queue.capacity.max_queue_size_in_bytes)
	PAGE_CAPACITY=$(curl -s "$LOGSTASH_HOST:$LOGSTASH_PORT/_node/stats" | jq .pipelines.main.queue.capacity.page_capacity_in_bytes)
	QUEUE_SIZE=$(curl -s "$LOGSTASH_HOST:$LOGSTASH_PORT/_node/stats" | jq .pipelines.main.queue.capacity.queue_size_in_bytes)
	QUEUE_TYPE=$(curl -s "$LOGSTASH_HOST:$LOGSTASH_PORT/_node/stats" | jq .pipelines.main.queue.type | sed s/\"//g)
	QUEUE_EVENTS=$(curl -s "$LOGSTASH_HOST:$LOGSTASH_PORT/_node/stats" | jq .pipelines.main.queue.events)
        EVENTS_IN=$(curl -s "$LOGSTASH_HOST:$LOGSTASH_PORT/_node/stats" | jq .events.in)
	EVENTS_OUT=$(curl -s "$LOGSTASH_HOST:$LOGSTASH_PORT/_node/stats" | jq .events.out)
	echo
        header "Logstash"
		if [ "$LS_RUNNING" ];then
                	echo && echo "Logstash is running." && echo
			docker stats --no-stream so-logstash
			echo
			echo "Logstash Queue Stats:"
			echo
			#echo Storage Type: $QUEUE_STORAGE_TYPE
			#echo Free Space: $(($QUEUE_FREE_SPACE/10**6))MB
			if [ "$QUEUE_TYPE" != "null" ]; then
				echo Queue Type: $QUEUE_TYPE
				if [ "$QUEUE_TYPE" == "persisted" ]; then
					echo Queue Path: $QUEUE_PATH
					echo Queue Size: $(($QUEUE_SIZE/10**6))MB
					echo Max Queue Size: $(($QUEUE_MAX_SIZE/10**6))
					echo Events in Queue: $QUEUE_EVENTS
					#echo Maximum Unread Events: $QUEUE_MAX_UNREAD
                        		#echo Page Capacity: $(($PAGE_CAPACITY/10**6))MB
				fi
				echo "Queue settings can be modified in /etc/logstash/logstash.yml." 	
			
				echo
				echo "Event Summary (since restart):"
				echo
				echo "Events In: $EVENTS_IN"
				echo "Events Out: $EVENTS_OUT"
				echo
			else
				echo "Logstash has started, but has not completed initialization."
				echo "To obtain queue stats, try running sostat again in a few minutes."
			fi
		else
			echo && echo -e "Logstash is not running.\n\nTry starting it with:\n\n'sudo so-elastic-start'\n OR\n'sudo so-logstash-start'\n\n\nIf that does not work, try checking /var/log/logstash/logstash.log for clues."
        	fi
	fi

	if [ "$LOGSTASH_OUTPUT_REDIS" = "yes" ]; then
	echo
	header "Redis"
		echo
		if pgrep redis-server >/dev/null 2>&1; then
			echo -n "Logs in redis: "
			redis-cli LLEN logstash:redis
		else
			echo "Redis is NOT running.  You can try starting it with:"
			echo "sudo service redis-server start"
		fi
	fi

	if [ "$KIBANA_ENABLED" = "yes" ]; then
        echo
	header "Kibana"
		if [ "$KIB_RUNNING" ]; then
			echo && echo "Kibana is running."
		echo
			docker stats --no-stream so-kibana
		else
			echo && echo -e "Kibana is not running.\n\nTry starting it with:\n\n'sudo so-elastic-start'\n OR\n'sudo so-kibana-start'\n\n\nIf that does not work, try checking /var/log/kibana/kibana.log for clues."
        	fi
	fi

        if [ "$ELASTALERT_ENABLED" = "yes" ]; then
        echo
        header "ElastAlert"
	        if [ "$ELAST_RUNNING" ]; then
			echo && echo "ElastAlert is running."
			echo
                        docker stats --no-stream so-elastalert
                else
			echo && echo -e "ElastAlert is not running.\n\nTry starting it with:\n\n'sudo so-elastic-start'\n OR\n'sudo so-elastalert-start'\n\n\nIf that does not work, try checking /var/log/elastalert/elastalert_stderr.log for clues."
                fi
        fi

	if [ "$CURATOR_ENABLED" = "yes" ]; then
	echo
        header "Curator"
		if [ "$CURAT_RUNNING" ]; then
                        echo && echo "Curator is running."
                        echo
                        docker stats --no-stream so-curator
                else
                        echo && echo -e "Curator is not running.\n\nTry starting it with:\n\n'sudo so-elastic-start'\n OR\n'sudo so-curator-start'\n\n\nIf that does not work, try checking /var/log/curator/curator.log for clues."
                fi
        fi
	
	if [ "$FREQ_SERVER_ENABLED" = "yes" ]; then
        echo
        header "Freq Server"
	        if [ "$FREQ_RUNNING" ]; then
                        echo && echo "Freq_server is running."
                        echo
                        docker stats --no-stream so-freqserver
			echo
			echo "Testing freq_server now..."
			FREQ_SERVER_RESPONSE=`docker exec -it so-logstash curl -s http://so-freqserver:10004/measure/google.com` | awk '{print $2}'| cut -d ')' -f1
                        FREQ_RESULT=$(awk -vx=$FREQ_SERVER_RESPONSE 'BEGIN{ print x>=y?1:0}')
                        if [[ "$FREQ_RESULT" -eq 1 ]]; then
				echo
				echo "Freq Server is working."
			else
				echo
				echo "Freq_server is not running.\n\nTry starting it with:\n\n'sudo so-elastic-start'\n OR\n'sudo so-freqserver-start'\n\n\nIf that does not work, try checking /var/log/freq_server/freq_server.log for clues."
			fi
                else
                        echo && echo -e "Freq_server is not running.\n\nTry starting it with:\n\n'sudo so-elastic-start'\n OR\n'sudo so-freqserver-start'\n\n\nIf that does not work, try checking /var/log/freq_server/freq_server.log for clues."
                fi
	fi
	
	if [ "$DOMAIN_STATS_ENABLED" = "yes" ]; then
        echo
        header "Domain Stats"
	        if [ "$DOMAINSTATS_RUNNING" ]; then
                        echo && echo "Domain_stats is running."
                        echo
                        docker stats --no-stream so-domainstats
			echo
			echo "Testing domain_stats now..."
			DOMAIN_STATS_RESPONSE=`docker exec so-logstash curl -s http://so-domainstats:20000/alexa/google.com`
			DOMAIN_STATS_RESULT=$(awk -vx=$DOMAIN_STATS_RESPONSE 'BEGIN{ print x>=y?1:0}')
			if [[ "$DOMAIN_STATS_RESULT" -eq 1 ]]; then
				echo
				echo "Domain_stats is working."
			else
				echo
				echo "Domain_stats is not running.\n\nTry starting it with:\n\n'sudo so-elastic-start'\n OR\n'sudo so-domainstats-start'\n\n\nIf that does not work, try checking /var/log/domain_stats/domain_stats.log for clues."
			fi
                else
                        echo && echo -e "Domain_stats is not running.\n\nTry starting it with:\n\n'sudo so-elastic-start'\n OR\n'sudo so-domainstats-start'\n\n\nIf that does not work, try checking /var/log/domain_stats/domain_stats.log for clues."
                fi
        fi
	if [ "$ES_RUNNING" ]; then
		if [ $(/usr/sbin/so-crossclustercheck | jq "." | grep -B3 ":5" |grep -v "\"seeds\"" | grep -v "skip_unavailable" | grep -v "^--" | paste -d " " - - | wc -l) -gt 0 ]; then
	                echo
        	        header "Cross Cluster Search"
			/usr/sbin/so-crossclustercheck | jq "." | grep -B3 ":5" |grep -v "\"seeds\"" | grep -v "skip_unavailable" | grep -v "^--" | paste -d " " - - | while read i; do
                        	SEED_NAME=`echo $i | cut -d\" -f2`
	                        SEED_PAIR=`echo $i | cut -d\" -f4`
        	                SEED_IP=`echo $i | cut -d\" -f4  | cut -d: -f1`
                	        SEED_PORT=`echo $i | cut -d\" -f4 | cut -d: -f2`
                        	if nc -vz $SEED_IP $SEED_PORT > /dev/null 2>&1; then
                                	STATUS="CONNECTED"
	                        else
        	                        STATUS="NOT CONNECTED"
                	        fi
				echo
                        	echo $SEED_NAME - $SEED_PAIR  - $STATUS
        	        done
	        fi
	fi
fi

# securityonion-sostat: check for syslog-ng drops #1660
# https://github.com/Security-Onion-Solutions/security-onion/issues/1660
if pgrep syslog-ng >/dev/null; then
	echo
	header "syslog-ng stats"
	echo
	syslog-ng-ctl stats |grep -v ";0$"
	TOTAL_DROPPED=0
	for LINE in $(syslog-ng-ctl stats |grep ";dropped;"); do 
		DROPPED=$(echo $LINE | cut -d\; -f6)
		let TOTAL_DROPPED=TOTAL_DROPPED+DROPPED
	done
	if [ $TOTAL_DROPPED -gt 0 ]; then
		echo
		echo "WARNING! syslog-ng reports drops!"
		syslog-ng-ctl stats |grep ";dropped;" | grep -v ";dropped;0$"
	fi
fi

if [ -f /etc/timezone ] && ! grep "Etc/UTC" /etc/timezone >/dev/null 2>&1; then
	echo
	header "Time Zone"
	echo "WARNING! Timezone is NOT set to UTC!"
	echo "Please see:"
	echo "https://securityonion.net/docs/TimeZones"
fi

FILE="/etc/os-release"
if [ -f $FILE ]; then
	source $FILE
	echo
	header "Version Information"
	echo
	echo $PRETTY_NAME
	if [[ $ALL_PKGS == 1 ]]; then
		echo
		header "All Installed Security Onion Packages"
		dpkg -l | grep securityonion | awk '{print $2,$3}'
	else
		dpkg -l |grep sostat | awk '{print $2,$3}'
	fi
fi
echo
